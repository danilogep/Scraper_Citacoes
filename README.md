# SCRAPER CITA√á√ïES
Um web scraper desenvolvido em Python que navega por um site de cita√ß√µes, extrai informa√ß√µes estruturadas e as salva em um arquivo CSV.

Este projeto faz a coleta de dados na web, incluindo a realiza√ß√£o de requisi√ß√µes HTTP e a navega√ß√£o autom√°tica por m√∫ltiplas p√°ginas (pagina√ß√£o). √â uma demonstra√ß√£o pr√°tica de como construir ferramentas de automa√ß√£o para a extra√ß√£o de dados da internet.

‚ú® Funcionalidades
1. Extra√ß√£o de Dados: Coleta o texto da cita√ß√£o, o nome do autor e as tags associadas.
2. Pagina√ß√£o Autom√°tica: Navega de forma aut√¥noma por todas as p√°ginas do site, seguindo o link "Next" at√© a √∫ltima p√°gina.
3. Armazenamento Estruturado: Salva todos os dados coletados em um arquivo .csv limpo e bem formatado, pronto para ser usado em planilhas ou an√°lises de dados.

üéØ Alvo do Scraper: O script foi desenvolvido para extrair dados do site http://quotes.toscrape.com. Este site √© um "sandbox" (ambiente de testes) mantido especificamente para fins educacionais, permitindo a pr√°tica de web scraping de forma legal e √©tica, sem violar termos de servi√ßo ou sobrecarregar servidores de produ√ß√£o.

üõ†Ô∏è Tecnologias Utilizadas
1. Python 3: Linguagem principal do projeto.
2. requests: Biblioteca para realizar as requisi√ß√µes HTTP e fazer o download do conte√∫do HTML das p√°ginas.
3. Beautiful Soup 4: A principal biblioteca de parsing utilizada para navegar na estrutura do documento HTML e extrair os dados de interesse de forma eficiente.

‚öôÔ∏è Como Usar
1. Instala√ß√£o e Execu√ß√£o

Fa√ßa o clone este reposit√≥rio: https://github.com/danilogep/Scraper_Citacoes.git

Acesse o cd [NOME-DO-SEU-REPOSITORIO]

Instale as bibliotecas requests e beautifulsoup4. Instale-as com o seguinte comando: pip install requests beautifulsoup4

Execute o script: python scraper_citacoes.py
Ao final, o arquivo citacoes.csv ser√° criado na mesma pasta.

